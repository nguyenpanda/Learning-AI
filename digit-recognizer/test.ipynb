{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    " \n",
    "data = pd.read_csv('train.csv')\n",
    "data = np.array(data)\n",
    "dataFrame = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = (784, 33600) | Y_train = (1, 33600)\n",
      "X_test = (784, 8400)   | Y_test = (1, 8400)\n"
     ]
    }
   ],
   "source": [
    "def splitData(data: np.ndarray, train_percent=0.8):\n",
    "    m, n = data.shape\n",
    "    numSplit = int(42000 * train_percent)\n",
    "    \n",
    "    train = data[0:numSplit].T\n",
    "    y_train = train[0:1]\n",
    "    x_train = train[1:n] / 255\n",
    "    \n",
    "    test = data[numSplit:m].T\n",
    "    y_test = test[0:1]\n",
    "    x_test = test[1:n] / 255\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "   \n",
    "x_train, y_train, x_test, y_test = splitData(data)\n",
    "print(f'X_train = {x_train.shape} | Y_train = {y_train.shape}')\n",
    "print(f'X_test = {x_test.shape}   | Y_test = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameter(m: int, node_per_layer=10):\n",
    "    \n",
    "    w1 = np.random.rand(node_per_layer, m) - 0.5\n",
    "    b1 = np.random.rand(node_per_layer, 1) - 0.5\n",
    "    \n",
    "    w2 = np.random.rand(node_per_layer, node_per_layer) - 0.5\n",
    "    b2 = np.random.rand(node_per_layer, 1) - 0.5\n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def ReUL(z: np.ndarray) -> np.ndarray:\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def ReUL_der(z: np.ndarray) -> np.ndarray:\n",
    "    return z >= 0\n",
    "\n",
    "def softMax(z: np.ndarray) -> np.ndarray:\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x: np.ndarray, \n",
    "                        w1: np.ndarray, b1: np.ndarray, \n",
    "                        w2: np.ndarray, b2: np.ndarray):\n",
    "    \n",
    "    z1 = w1 @ x + b1\n",
    "    a1 = ReUL(z1)\n",
    "    \n",
    "    z2 = w2 @ a1 + b2\n",
    "    a2 = softMax(z2)\n",
    "    \n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "def Y_boolean_vector(y):\n",
    "    boolean = np.zeros([y.size, 10]) # (33600, 10)\n",
    "    boolean[np.arange(y.size), y] = 1\n",
    "    boolean = boolean.T\n",
    "    return boolean # (10, 33600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(x: np.ndarray, y: np.ndarray,\n",
    "                         z1: np.ndarray, w1: np.ndarray, a1: np.ndarray,\n",
    "                         z2: np.ndarray, w2: np.ndarray, a2: np.ndarray):\n",
    "    m = y.size\n",
    "    dz_2 = a2 - Y_boolean_vector(y)\n",
    "    # print(f'dz_2 = {dz_2.shape}')\n",
    "    dw_2 = dz_2 @ a1.T / m\n",
    "    # print(f'dw_2 = {dw_2.shape}')\n",
    "    db_2 = np.sum(dz_2, axis=1, keepdims=True) / m\n",
    "    # print(f'db_2 = {db_2.shape}')\n",
    "    dz_1 = w2.T @ dz_2 * ReUL_der(z1)\n",
    "    # print(f'dz_1 = {dz_1.shape}')\n",
    "    dw_1 = dz_1 @ x.T / m\n",
    "    # print(f'dw_1 = {dw_1.shape}')\n",
    "    db_1 = np.sum(dz_1) / m\n",
    "    # print(f'db_1 = {db_1.shape}')\n",
    "    return dw_1, db_1, dw_2, db_2\n",
    "\n",
    "def update_parameters(w1: np.ndarray, b1: np.ndarray, w2: np.ndarray, b2: np.ndarray,\n",
    "                     dw_1: np.ndarray, db_1: np.ndarray, dw_2: np.ndarray, db_2: np.ndarray,\n",
    "                     alpha: float):\n",
    "    b1 = b1 - alpha * db_1\n",
    "    b2 = b2 - alpha * db_2\n",
    "    \n",
    "    w2 = w2 - alpha * dw_2\n",
    "    w1 = w1 - alpha * dw_1\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(a2: np.ndarray):\n",
    "    return np.argmax(a2, 0)\n",
    "\n",
    "def accuracy(predictions, y: np.ndarray):\n",
    "    return np.sum(predictions == y) / y.size\n",
    "\n",
    "def gradient_descent(X: np.ndarray, Y: np.ndarray, alpha: float, iterations: int):\n",
    "    w1, b1, w2, b2 = init_parameter(X.shape[0])\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z1, a1, z2, a2 = forward_propagation(X, w1, b1, w2, b2)\n",
    "        dw1, db1, dw2, db2 = backward_propagation(X, Y, z1, w1, a1, z2, w2, a2)\n",
    "        w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = prediction(a2)\n",
    "            print(f'Accuracy: {accuracy(predictions, Y)}')\n",
    "            \n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X: np.ndarray, \n",
    "                     w1: np.ndarray, b1: np.ndarray, \n",
    "                     w2: np.ndarray, b2: np.ndarray):\n",
    "    \n",
    "    _, _, _, a2 = forward_propagation(X, w1, b1, w2, b2)\n",
    "    predictions = prediction(a2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index: int, \n",
    "                    w1: np.ndarray, b1: np.ndarray, \n",
    "                    w2: np.ndarray, b2: np.ndarray):\n",
    "    \n",
    "    prediction = make_predictions(x_train[:, index, None], w1, b1, w2, b2)\n",
    "    label = y_train[0][index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = x_train[:, index, None]\n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    \n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "def export_parameters_as_csv(W1: np.ndarray, B1: np.ndarray, \n",
    "                      W2: np.ndarray, B2: np.ndarray,\n",
    "                      alpha: float, iterations: int):\n",
    "    \n",
    "    file_path = ['w1', 'b1', 'w2', 'b2']\n",
    "    parameters_export = [W1, B1, W2, B2]\n",
    "\n",
    "    for i in range(len(file_path)):\n",
    "        m, n = parameters_export[i].shape\n",
    "        file_path[i] = 'Parameters/' + file_path[i] + f'_{m}x{n}_a{alpha}_i{iterations}' + '.csv'\n",
    "        \n",
    "    print(file_path)\n",
    "    \n",
    "    for i in range(len(file_path)):\n",
    "        np.savetxt(file_path[i], parameters_export[i], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy: 0.11648809523809524\n",
      "Iteration:  100\n",
      "Accuracy: 0.6519047619047619\n",
      "Iteration:  200\n",
      "Accuracy: 0.7730952380952381\n",
      "Iteration:  300\n",
      "Accuracy: 0.8161309523809523\n",
      "Iteration:  400\n",
      "Accuracy: 0.8395535714285715\n",
      "Iteration:  500\n",
      "Accuracy: 0.8533928571428572\n",
      "Iteration:  600\n",
      "Accuracy: 0.8623511904761905\n",
      "Iteration:  700\n",
      "Accuracy: 0.8694642857142857\n",
      "Iteration:  800\n",
      "Accuracy: 0.8751785714285715\n",
      "Iteration:  900\n",
      "Accuracy: 0.8798214285714285\n",
      "Iteration:  1000\n",
      "Accuracy: 0.883125\n",
      "Iteration:  1100\n",
      "Accuracy: 0.8872619047619048\n",
      "Iteration:  1200\n",
      "Accuracy: 0.890327380952381\n",
      "Iteration:  1300\n",
      "Accuracy: 0.8927380952380952\n",
      "Iteration:  1400\n",
      "Accuracy: 0.8951488095238095\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = gradient_descent(x_train, y_train, 0.1, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet Accuracy: 0.8964285714285715\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_, _, _, a2_test = forward_propagation(x_test, w1, b1, w2, b2)\n",
    "\n",
    "predictions_test = prediction(a2_test)\n",
    "print(f'DataSet Accuracy: {accuracy(predictions_test, y_test)}')\n",
    "\n",
    "# export_parameters_as_csv(w1, b1, w2, b2, 0.01, 10001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_2(X: np.ndarray, Y: np.ndarray, \n",
    "                     w1: np.ndarray, b1: np.ndarray, w2: np.ndarray, b2: np.ndarray,\n",
    "                     alpha: float, iterations: int):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z1, a1, z2, a2 = forward_propagation(X, w1, b1, w2, b2)\n",
    "        dw1, db1, dw2, db2 = backward_propagation(X, Y, z1, w1, a1, z2, w2, a2)\n",
    "        w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = prediction(a2)\n",
    "            print(f'Accuracy: {accuracy(predictions, Y)}')\n",
    "            \n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy: 0.8971428571428571\n",
      "Iteration:  100\n",
      "Accuracy: 0.8993452380952381\n",
      "Iteration:  200\n",
      "Accuracy: 0.9011011904761905\n",
      "Iteration:  300\n",
      "Accuracy: 0.9023511904761905\n",
      "Iteration:  400\n",
      "Accuracy: 0.9036904761904762\n",
      "Iteration:  500\n",
      "Accuracy: 0.9050892857142857\n",
      "Iteration:  600\n",
      "Accuracy: 0.9063988095238096\n",
      "Iteration:  700\n",
      "Accuracy: 0.9072916666666667\n",
      "Iteration:  800\n",
      "Accuracy: 0.90875\n",
      "Iteration:  900\n",
      "Accuracy: 0.9095833333333333\n"
     ]
    }
   ],
   "source": [
    "w1_2, b1_2, w2_2, b2_2 = gradient_descent_2(x_train, y_train, w1, b1, w2, b2, 0.1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet Accuracy: 0.9080952380952381\n"
     ]
    }
   ],
   "source": [
    "_, _, _, a2_test = forward_propagation(x_test, w1_2, b1_2, w2_2, b2_2)\n",
    "\n",
    "predictions_test = prediction(a2_test)\n",
    "print(f'DataSet Accuracy: {accuracy(predictions_test, y_test)}')\n",
    "\n",
    "# export_parameters_as_csv(w1_2, b1_2, w2_2, b2_2, 0.1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy: 0.910625\n",
      "Iteration:  100\n",
      "Accuracy: 0.9117559523809524\n",
      "Iteration:  200\n",
      "Accuracy: 0.9133630952380952\n",
      "Iteration:  300\n",
      "Accuracy: 0.9169047619047619\n",
      "Iteration:  400\n",
      "Accuracy: 0.9195535714285714\n",
      "Iteration:  500\n",
      "Accuracy: 0.9213690476190476\n",
      "Iteration:  600\n",
      "Accuracy: 0.9220535714285715\n",
      "Iteration:  700\n",
      "Accuracy: 0.9245238095238095\n",
      "Iteration:  800\n",
      "Accuracy: 0.9258630952380953\n",
      "Iteration:  900\n",
      "Accuracy: 0.9272916666666666\n",
      "Iteration:  1000\n",
      "Accuracy: 0.9283035714285715\n",
      "Iteration:  1100\n",
      "Accuracy: 0.929672619047619\n",
      "Iteration:  1200\n",
      "Accuracy: 0.930327380952381\n",
      "Iteration:  1300\n",
      "Accuracy: 0.9315178571428572\n",
      "Iteration:  1400\n",
      "Accuracy: 0.9324107142857143\n",
      "Iteration:  1500\n",
      "Accuracy: 0.933125\n",
      "Iteration:  1600\n",
      "Accuracy: 0.9338392857142858\n",
      "Iteration:  1700\n",
      "Accuracy: 0.9346130952380952\n",
      "Iteration:  1800\n",
      "Accuracy: 0.9354761904761905\n",
      "Iteration:  1900\n",
      "Accuracy: 0.9360119047619048\n"
     ]
    }
   ],
   "source": [
    "w1_3, b1_3, w2_3, b2_3 = gradient_descent_2(x_train, y_train, w1_2, b1_2, w2_2, b2_2, 0.3, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet Accuracy: 0.9275\n"
     ]
    }
   ],
   "source": [
    "_, _, _, a2_test = forward_propagation(x_test, w1_3, b1_3, w2_3, b2_3)\n",
    "\n",
    "predictions_test = prediction(a2_test)\n",
    "print(f'DataSet Accuracy: {accuracy(predictions_test, y_test)}')\n",
    "\n",
    "# export_parameters_as_csv(w1_3, b1_3, w2_3, b2_3, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy: 0.936577380952381\n",
      "Iteration:  100\n",
      "Accuracy: 0.9354464285714286\n",
      "Iteration:  200\n",
      "Accuracy: 0.9369047619047619\n",
      "Iteration:  300\n",
      "Accuracy: 0.9373809523809524\n",
      "Iteration:  400\n",
      "Accuracy: 0.9394642857142858\n",
      "Iteration:  500\n",
      "Accuracy: 0.9403869047619048\n",
      "Iteration:  600\n",
      "Accuracy: 0.9410714285714286\n",
      "Iteration:  700\n",
      "Accuracy: 0.9416666666666667\n",
      "Iteration:  800\n",
      "Accuracy: 0.9427678571428572\n",
      "Iteration:  900\n",
      "Accuracy: 0.9423214285714285\n",
      "Iteration:  1000\n",
      "Accuracy: 0.9433630952380953\n",
      "Iteration:  1100\n",
      "Accuracy: 0.9439285714285715\n",
      "Iteration:  1200\n",
      "Accuracy: 0.9446130952380952\n",
      "Iteration:  1300\n",
      "Accuracy: 0.945297619047619\n",
      "Iteration:  1400\n",
      "Accuracy: 0.9453571428571429\n",
      "Iteration:  1500\n",
      "Accuracy: 0.9447916666666667\n",
      "Iteration:  1600\n",
      "Accuracy: 0.9460714285714286\n",
      "Iteration:  1700\n",
      "Accuracy: 0.9466071428571429\n",
      "Iteration:  1800\n",
      "Accuracy: 0.9463392857142857\n",
      "Iteration:  1900\n",
      "Accuracy: 0.9470535714285714\n"
     ]
    }
   ],
   "source": [
    "w1_4, b1_4, w2_4, b2_4 = gradient_descent_2(x_train, y_train, w1_3, b1_3, w2_3, b2_3, 0.5, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy: 0.9476190476190476\n",
      "Iteration:  100\n",
      "Accuracy: 0.9479761904761905\n",
      "Iteration:  200\n",
      "Accuracy: 0.9486904761904762\n",
      "Iteration:  300\n",
      "Accuracy: 0.9232440476190477\n",
      "Iteration:  400\n",
      "Accuracy: 0.9491964285714286\n",
      "Iteration:  500\n",
      "Accuracy: 0.9494642857142858\n",
      "Iteration:  600\n",
      "Accuracy: 0.9497619047619048\n",
      "Iteration:  700\n",
      "Accuracy: 0.9462797619047619\n",
      "Iteration:  800\n",
      "Accuracy: 0.9502678571428571\n",
      "Iteration:  900\n",
      "Accuracy: 0.934047619047619\n",
      "Iteration:  1000\n",
      "Accuracy: 0.9510416666666667\n",
      "Iteration:  1100\n",
      "Accuracy: 0.9516071428571429\n",
      "Iteration:  1200\n",
      "Accuracy: 0.9516666666666667\n",
      "Iteration:  1300\n",
      "Accuracy: 0.9517559523809523\n",
      "Iteration:  1400\n",
      "Accuracy: 0.9491666666666667\n",
      "Iteration:  1500\n",
      "Accuracy: 0.9521726190476191\n",
      "Iteration:  1600\n",
      "Accuracy: 0.9416369047619048\n",
      "Iteration:  1700\n",
      "Accuracy: 0.9528571428571428\n",
      "Iteration:  1800\n",
      "Accuracy: 0.9499107142857143\n",
      "Iteration:  1900\n",
      "Accuracy: 0.9531845238095238\n",
      "Iteration:  2000\n",
      "Accuracy: 0.9534523809523809\n",
      "Iteration:  2100\n",
      "Accuracy: 0.9536607142857143\n",
      "Iteration:  2200\n",
      "Accuracy: 0.9539583333333334\n",
      "Iteration:  2300\n",
      "Accuracy: 0.9542559523809524\n",
      "Iteration:  2400\n",
      "Accuracy: 0.9536011904761905\n",
      "Iteration:  2500\n",
      "Accuracy: 0.9534523809523809\n",
      "Iteration:  2600\n",
      "Accuracy: 0.9547619047619048\n",
      "Iteration:  2700\n",
      "Accuracy: 0.951577380952381\n",
      "Iteration:  2800\n",
      "Accuracy: 0.9552678571428571\n",
      "Iteration:  2900\n",
      "Accuracy: 0.9532142857142857\n",
      "Iteration:  3000\n",
      "Accuracy: 0.955654761904762\n",
      "Iteration:  3100\n",
      "Accuracy: 0.955654761904762\n",
      "Iteration:  3200\n",
      "Accuracy: 0.9555654761904762\n",
      "Iteration:  3300\n",
      "Accuracy: 0.9554166666666667\n",
      "Iteration:  3400\n",
      "Accuracy: 0.9551785714285714\n",
      "Iteration:  3500\n",
      "Accuracy: 0.955654761904762\n",
      "Iteration:  3600\n",
      "Accuracy: 0.955952380952381\n",
      "Iteration:  3700\n",
      "Accuracy: 0.9544047619047619\n",
      "Iteration:  3800\n",
      "Accuracy: 0.9562797619047619\n",
      "Iteration:  3900\n",
      "Accuracy: 0.9572619047619048\n",
      "Iteration:  4000\n",
      "Accuracy: 0.9557142857142857\n",
      "Iteration:  4100\n",
      "Accuracy: 0.9574404761904762\n",
      "Iteration:  4200\n",
      "Accuracy: 0.9561904761904761\n",
      "Iteration:  4300\n",
      "Accuracy: 0.9576488095238095\n",
      "Iteration:  4400\n",
      "Accuracy: 0.9575\n",
      "Iteration:  4500\n",
      "Accuracy: 0.9554761904761905\n",
      "Iteration:  4600\n",
      "Accuracy: 0.9579166666666666\n",
      "Iteration:  4700\n",
      "Accuracy: 0.955654761904762\n",
      "Iteration:  4800\n",
      "Accuracy: 0.9575297619047619\n",
      "Iteration:  4900\n",
      "Accuracy: 0.9575595238095238\n"
     ]
    }
   ],
   "source": [
    "w1_5, b1_5, w2_5, b2_5 = gradient_descent_2(x_train, y_train, w1_4, b1_4, w2_4, b2_4, 0.5, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet Accuracy: 0.949952380952381\n",
      "['Final_Parameters_95/w1_10x784.csv', 'Final_Parameters_95/b1_10x1.csv', 'Final_Parameters_95/w2_10x10.csv', 'Final_Parameters_95/b2_10x1.csv']\n"
     ]
    }
   ],
   "source": [
    "# final\n",
    "m, n = data.shape\n",
    "final = data[0:m].T\n",
    "y_final = final[0:1]\n",
    "x_final = final[1:n] / 255\n",
    "_, _, _, a2_final = forward_propagation(x_final, w1_5, b1_5, w2_5, b2_5)\n",
    "\n",
    "predictions_final = prediction(a2_final)\n",
    "print(f'DataSet Accuracy: {accuracy(predictions_final, y_final)}')\n",
    "    \n",
    "file_path = ['w1', 'b1', 'w2', 'b2']\n",
    "parameters_export = [w1_3, b1_3, w2_3, b2_3]\n",
    "\n",
    "for i in range(len(file_path)):\n",
    "    m_size, n_size = parameters_export[i].shape\n",
    "    file_path[i] = 'Final_Parameters_95/' + file_path[i] + f'_{m_size}x{n_size}' + '.csv'\n",
    "    \n",
    "print(file_path)\n",
    "\n",
    "for i in range(len(file_path)):\n",
    "    np.savetxt(file_path[i], parameters_export[i], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [0]\n",
      "Label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(np.random.randint(0, 3000), w1_3, b1_3, w2_3, b2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Accuracy\n",
    "- Achieved an impressive accuracy of 93.92%.\n",
    "\n",
    "## Model Architecture\n",
    "- **Input Layer:** Consists of 784 nodes.\n",
    "- **Hidden Layers:**\n",
    "  1. First hidden layer: Rectified Linear Unit (ReUL) activation function, with 10 nodes.\n",
    "  2. Second hidden layer: Softmax activation function, also with 10 nodes.\n",
    "- **Output Layer:** Comprises 10 nodes for prediction.\n",
    "\n",
    "## Model Parameters\n",
    "- **w1:** Weight matrix with dimensions (10, 784).\n",
    "- **b1:** Bias vector with dimensions (10, 1).\n",
    "- **w2:** Weight matrix with dimensions (10, 10).\n",
    "- **b2:** Bias vector with dimensions (10, 1).\n",
    "\n",
    "These results demonstrate the effectiveness of the model architecture and the successful optimization of parameters, leading to a high level of accuracy in predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
